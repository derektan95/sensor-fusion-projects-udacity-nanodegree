# Tutorial for Sensor Fusion Nanodegree - Udacity Course

Date Attempted: 5th July 2020

**Summary**<br/>
This is a course that summarizes the essential principles of LiDAR, Camera, Radar and Sensor Fusion. It contains my own implementaion of functions necessary to pass the project specifications of the udacity project.

**LiDAR Segment**<br/>
The main principles taught in this segment are: 
1) Plane Segmentation
2) Euclidean Clustering using kd-tree
3) Filtering techniques
4) Reading and streaming PCDs

**Camera Segment**<br/>
The main principles taught in this segment are: 
1) Camera Technology & Optics
2) Autonomous Vehicles & Computer Vision 
3) Engineering a Collision Detection System (Time To Collision)
4) Tracking Image Features (Detectors, Descriptors, Matchers, Selectors)
5) Introduction to Object Detection Frameworks - YOLO
6) Sensor Fusion - Camera + LiDAR

**Radar Segment**<br/>
The main principles taught in this segment are: 
1) Radar Principles
2) Using Fast-Fourier Transform to obtain Range (Distance) and Doppler (Velocity) information
3) Removing clutter (noise), using Cell Averaging Constant Fast Alarm Rate (CA-CFAR)
4) Clustering and Tracking of Radar points
5) Simulation on Matlab

**Kalman Filter Segment**<br/>
The main principles taught in this segment are: 
1) Normal Kalman Filter (1D)
2) Extended Kalman Filter (2D)
3) Unscented Kalman Filter (2D)
